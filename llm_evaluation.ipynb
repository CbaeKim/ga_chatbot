{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "033d7354",
   "metadata": {},
   "source": [
    "# **Base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea33865b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ga_chatbot/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_chroma import Chroma\n",
    "from supabase import Client, create_client\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from app.routers.vectorstore import request_table, text_files_to_docs, docs_text_split, docs_insert_db, db_to_document\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "SUPABASE_URL = os.getenv('SUPABASE_URL')\n",
    "SUPABASE_API_KEY = os.getenv('SUPABASE_API_KEY')\n",
    "\n",
    "supabase: Client = create_client(supabase_url=SUPABASE_URL, supabase_key=SUPABASE_API_KEY)\n",
    "\n",
    "# Define Embedding Model\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name = 'FronyAI/frony-embed-large-ko-v1',\n",
    "    model_kwargs = {'device': 'mps'},\n",
    "    encode_kwargs = {'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "# Define Vectorstore path\n",
    "vectorstore_path = './ga_assistant_store'\n",
    "\n",
    "# Load Vectorstore\n",
    "vector_store = Chroma(\n",
    "    collection_name = \"ga_assistant\",\n",
    "    embedding_function = embedding,\n",
    "    persist_directory = vectorstore_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6222b3",
   "metadata": {},
   "source": [
    "# **Retriever Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d7b0ac",
   "metadata": {},
   "source": [
    "## **Retriever Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c37a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs = {'k': 3})\n",
    "\n",
    "CrossEncoder = HuggingFaceCrossEncoder(model_name = 'BAAI/bge-reranker-v2-m3')\n",
    "\n",
    "re_ranker = CrossEncoderReranker(\n",
    "    model = CrossEncoder,\n",
    "    top_n = 2\n",
    ")\n",
    "\n",
    "EmbeddingFilter = EmbeddingsFilter(\n",
    "    embeddings = embedding,\n",
    "    similarity_threshold = 0.3\n",
    ")\n",
    "\n",
    "compressor_pipeline = DocumentCompressorPipeline(\n",
    "    transformers = [re_ranker, EmbeddingFilter]\n",
    ")\n",
    "\n",
    "final_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor = compressor_pipeline,\n",
    "    base_retriever = retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe81375",
   "metadata": {},
   "source": [
    "## **Create Evaluation Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737127ef",
   "metadata": {},
   "source": [
    "### **Create Pydantic Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "312066ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"$defs\": {\"QAPair\": {\"properties\": {\"query\": {\"description\": \"AI가 생성한 질문 (write your question in KOREAN)\", \"title\": \"Query\", \"type\": \"string\"}, \"label\": {\"description\": \"질문의 대한 답 (write the answer to the fact_based question in KOREAN, making sure it reflects the essence of the question)\", \"title\": \"Label\", \"type\": \"string\"}}, \"required\": [\"query\", \"label\"], \"title\": \"QAPair\", \"type\": \"object\"}}, \"properties\": {\"qa_pairs\": {\"description\": \"query: label의 리스트\", \"items\": {\"$ref\": \"#/$defs/QAPair\"}, \"title\": \"Qa Pairs\", \"type\": \"array\"}}, \"required\": [\"qa_pairs\"]}\\n```'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# Load API Key\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "# Definition model object\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model = 'gemini-2.5-flash',         # model name\n",
    "    google_api_key = GEMINI_API_KEY,    # API KEY\n",
    "    temperature = 0.3\n",
    ")\n",
    "\n",
    "class QAPair(BaseModel):\n",
    "    query: str = Field(description = \"AI가 생성한 질문 (write your question in KOREAN)\")\n",
    "    label: str = Field(description = \"질문의 대한 답 (write the answer to the fact_based question in KOREAN, making sure it reflects the essence of the question)\")\n",
    "\n",
    "class QASet(BaseModel):\n",
    "    qa_pairs: List[QAPair] = Field(description = \"query: label의 리스트\")\n",
    "\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object = QASet)\n",
    "\n",
    "pydantic_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649dd152",
   "metadata": {},
   "source": [
    "### **Create Chain for get Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27e03b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_text = \"\"\n",
    "\n",
    "with open('./prompt/get_evaluation_data.txt', 'r') as f:\n",
    "    prompt_text = f.read()\n",
    "\n",
    "create_dataset_prompt = ChatPromptTemplate.from_template(\n",
    "    template = prompt_text,\n",
    "    partial_variables = {'format_instructions': pydantic_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = create_dataset_prompt | llm | pydantic_parser\n",
    "\n",
    "def create_dataset(context: str, num_questions: int) -> QASet:\n",
    "    \"\"\" Query functions using chains \"\"\"\n",
    "    return chain.invoke({'context': context, 'num_questions_per_chunk': num_questions})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f772081",
   "metadata": {},
   "source": [
    "### **Chain Execute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b487354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alert] All data get Success\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>context</th>\n",
       "      <th>file_name</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>총무팀 업무 메뉴얼을 안내합니다.\\n\\n[총무팀 구성원]\\n1. 이동훈님 (이메일:...</td>\n",
       "      <td>Guide_GA.txt</td>\n",
       "      <td>2025-08-22</td>\n",
       "      <td>이 문서는 어떤 내용을 안내하고 있습니까?</td>\n",
       "      <td>총무팀 업무 메뉴얼을 안내하고 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>총무팀 업무 메뉴얼을 안내합니다.\\n\\n[총무팀 구성원]\\n1. 이동훈님 (이메일:...</td>\n",
       "      <td>Guide_GA.txt</td>\n",
       "      <td>2025-08-22</td>\n",
       "      <td>총무팀 구성원 중 한 명의 이름은 무엇입니까?</td>\n",
       "      <td>이동훈님입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>총무팀 업무 메뉴얼을 안내합니다.\\n\\n[총무팀 구성원]\\n1. 이동훈님 (이메일:...</td>\n",
       "      <td>Guide_GA.txt</td>\n",
       "      <td>2025-08-22</td>\n",
       "      <td>이동훈님의 이메일 주소는 무엇입니까?</td>\n",
       "      <td>main3373@gmail.com입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>총무팀 업무 메뉴얼을 안내합니다.\\n\\n[총무팀 구성원]\\n1. 이동훈님 (이메일:...</td>\n",
       "      <td>Guide_GA.txt</td>\n",
       "      <td>2025-08-22</td>\n",
       "      <td>이동훈님의 연락처는 몇 번입니까?</td>\n",
       "      <td>010-3271-7132입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>총무팀 업무 메뉴얼을 안내합니다.\\n\\n[총무팀 구성원]\\n1. 이동훈님 (이메일:...</td>\n",
       "      <td>Guide_GA.txt</td>\n",
       "      <td>2025-08-22</td>\n",
       "      <td>이동훈님의 주요 역할 중 하나는 무엇입니까?</td>\n",
       "      <td>총무 일괄 지원입니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_id                                            context     file_name  \\\n",
       "0      1  총무팀 업무 메뉴얼을 안내합니다.\\n\\n[총무팀 구성원]\\n1. 이동훈님 (이메일:...  Guide_GA.txt   \n",
       "1      1  총무팀 업무 메뉴얼을 안내합니다.\\n\\n[총무팀 구성원]\\n1. 이동훈님 (이메일:...  Guide_GA.txt   \n",
       "2      1  총무팀 업무 메뉴얼을 안내합니다.\\n\\n[총무팀 구성원]\\n1. 이동훈님 (이메일:...  Guide_GA.txt   \n",
       "3      1  총무팀 업무 메뉴얼을 안내합니다.\\n\\n[총무팀 구성원]\\n1. 이동훈님 (이메일:...  Guide_GA.txt   \n",
       "4      1  총무팀 업무 메뉴얼을 안내합니다.\\n\\n[총무팀 구성원]\\n1. 이동훈님 (이메일:...  Guide_GA.txt   \n",
       "\n",
       "         date                      query                   label  \n",
       "0  2025-08-22    이 문서는 어떤 내용을 안내하고 있습니까?  총무팀 업무 메뉴얼을 안내하고 있습니다.  \n",
       "1  2025-08-22  총무팀 구성원 중 한 명의 이름은 무엇입니까?                이동훈님입니다.  \n",
       "2  2025-08-22       이동훈님의 이메일 주소는 무엇입니까?  main3373@gmail.com입니다.  \n",
       "3  2025-08-22         이동훈님의 연락처는 몇 번입니까?       010-3271-7132입니다.  \n",
       "4  2025-08-22   이동훈님의 주요 역할 중 하나는 무엇입니까?            총무 일괄 지원입니다.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get vectorstore latest data in supabase table\n",
    "df = request_table('vectorstore', db = supabase)\n",
    "df.drop(['id', 'source'], axis = 1, inplace = True)\n",
    "\n",
    "# final return variable\n",
    "qa_pairs = []\n",
    "\n",
    "# Process to get evaluation data\n",
    "for _, row in df.iterrows():\n",
    "    qa_pairs_row = create_dataset(row['page_content'], 10)\n",
    "    \n",
    "    for qa_pair_row in qa_pairs_row.qa_pairs:\n",
    "        # preprocess -> append\n",
    "        qa_pairs.append(\n",
    "            {\n",
    "                'doc_id': row['doc_id'],\n",
    "                'context': row['page_content'],\n",
    "                'file_name': row['file_name'],\n",
    "                'date': row['date'],\n",
    "                'query': qa_pair_row.query,\n",
    "                'label': qa_pair_row.label\n",
    "            }\n",
    "        )\n",
    "\n",
    "final_df = pd.DataFrame(qa_pairs)\n",
    "final_df.to_csv('./data/question_paper.csv', index = False)\n",
    "\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9affacea",
   "metadata": {},
   "source": [
    "## **Dataset preprocess**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c18547c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 샘플 추출: page_content='총무팀 업무 메뉴얼을 안내합니다.\n",
      "\n",
      "[총무팀 구성원]\n",
      "1. 이동훈님 (이메일: main3373@gmail.com, 연락처: 010-3271-7132)\n",
      " - 역할 : 총무 일괄 지원, IT 총무(PC, 소프트웨어 장애 등 IT 관련 지원)' metadata={'doc_id': ['1'], 'context': ['총무팀 업무 메뉴얼을 안내합니다.\\n\\n[총무팀 구성원]\\n1. 이동훈님 (이메일: main3373@gmail.com, 연락처: 010-3271-7132)\\n - 역할 : 총무 일괄 지원, IT 총무(PC, 소프트웨어 장애 등 IT 관련 지원)'], 'file_name': ['Guide_GA.txt'], 'date': ['2025-08-22']}\n",
      "Feature 샘플 추출: []\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# Convert DataFrame to Document\n",
    "def df_to_documents(df: pd.DataFrame, content_column: str, metadata_columns: List[str] = None) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Dataframe convert to Document object\n",
    "    - df: DataFrame\n",
    "    - content_column: will be page_content element\n",
    "    - metadata_columns = will be metadta -> Default None(All)\n",
    "    \"\"\"\n",
    "    if metadata_columns is None:\n",
    "        metadata_columns = [col for col in df.columns if col != content_column]\n",
    "\n",
    "    docs = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        page_content = row[content_column]\n",
    "        metadata = {col: [row[col]] for col in metadata_columns}\n",
    "        \n",
    "        docs.append(Document(page_content=str(page_content), metadata=metadata))\n",
    "\n",
    "    return docs\n",
    "\n",
    "metadata_list = ['doc_id', 'context', 'file_name', 'date']\n",
    "\n",
    "# Extract label docs: Column 'context'\n",
    "labels = df_to_documents(final_df, content_column = 'context', metadata_columns = metadata_list)\n",
    "\n",
    "# Feature: final_df['context']\n",
    "predicts = []\n",
    "\n",
    "for _, row in final_df.iterrows():\n",
    "    context = row['context']\n",
    "    query = row['query']\n",
    "\n",
    "    response = final_retriever.invoke(query)\n",
    "\n",
    "    predicts.append(response)\n",
    "\n",
    "print(f\"Label 샘플 추출: {labels[0]}\")\n",
    "print(f\"Feature 샘플 추출: {predicts[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9304a915",
   "metadata": {},
   "source": [
    "## **Create a function to calculate MRR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff5f35ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_mrr(label: Document, predict: List[Document]) -> float:\n",
    "    rank = 1\n",
    "\n",
    "    # Search rank\n",
    "    for doc in predict:\n",
    "        if doc.page_content == label.page_content:\n",
    "            return 1 / rank\n",
    "        \n",
    "        rank += 1\n",
    "    \n",
    "    # If no label, return 0.0\n",
    "    return 0.0\n",
    "\n",
    "def mrr_mean(labels: List[Document], predicts: List[List[Document]]) -> float:\n",
    "    max_range = len(labels)\n",
    "    \n",
    "    mrrs = []\n",
    "    \n",
    "    for i in range(0, max_range):\n",
    "        label = labels[i]\n",
    "        predict = predicts[i]\n",
    "\n",
    "        mrr = single_mrr(label = label, predict = predict)\n",
    "        mrrs.append(mrr)\n",
    "\n",
    "    mrr_mean = sum(mrrs) / len(mrrs)\n",
    "\n",
    "    return mrr_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ea6b0",
   "metadata": {},
   "source": [
    "## **Run calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8a706d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever의 평균 mrr 지표: 0.8625\n"
     ]
    }
   ],
   "source": [
    "result = mrr_mean(labels = labels, predicts = predicts)\n",
    "\n",
    "print(f\"Retriever의 평균 mrr 지표: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785f88ba",
   "metadata": {},
   "source": [
    "## **Appendix: Calling with API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe5cda19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.8625\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "BASE_URL = 'http://127.0.0.1:8000'\n",
    "ENDPOINT = '/evaluate_metrics/llm/mrrs_mean'\n",
    "\n",
    "# Preprocessing for data transmission\n",
    "labels_data = [{'page_content': doc.page_content, 'metadata': doc.metadata} for doc in labels]\n",
    "predicts_data = [[{'page_content': doc.page_content, 'metadata': doc.metadata} for doc in sublist] for sublist in predicts]\n",
    "\n",
    "# Convert to type: json\n",
    "payload = {'labels': labels_data, 'predicts': predicts_data}\n",
    "\n",
    "# request\n",
    "response = requests.post(f\"{BASE_URL}{ENDPOINT}\", json = payload, timeout = 20)\n",
    "\n",
    "# response output\n",
    "print(f\"MRR: {response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fce9294",
   "metadata": {},
   "source": [
    "# **LLM Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450e96ad",
   "metadata": {},
   "source": [
    "## **Run predicts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44354cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_llm(query):\n",
    "    BASE_URL = 'http://127.0.0.1:8000'\n",
    "    ENDPOINT = '/request/rag_model/lcel'\n",
    "\n",
    "    payload = {'input_text': query}\n",
    "\n",
    "    response = requests.post(f\"{BASE_URL}{ENDPOINT}\", json = payload, timeout = 600).text\n",
    "\n",
    "    return response\n",
    "\n",
    "questions = final_df['query']\n",
    "labels = final_df['label']\n",
    "\n",
    "predicts = []\n",
    "\n",
    "for question in questions:\n",
    "    result = request_llm(question)\n",
    "    predicts.append(result)\n",
    "\n",
    "final_df['predict'] = predicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64780b36",
   "metadata": {},
   "source": [
    "## **Evaluator Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b75011a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import load_evaluator, EvaluatorType\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "gpt = ChatOpenAI(model = 'gpt-4o-mini', temperature = 0.1)\n",
    "\n",
    "evaluator_qa = load_evaluator(evaluator = 'qa', llm = gpt)\n",
    "evaluator_context_qa = load_evaluator(evaluator = 'context_qa', llm = gpt)\n",
    "evaluator_cot_qa = load_evaluator(evaluator = 'cot_qa', llm = gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd48c00",
   "metadata": {},
   "source": [
    "## **Run Evaluator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88ce0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Feature, Predictions, labels\n",
    "query = final_df['query']\n",
    "predictions = final_df['predict']\n",
    "labels = final_df['label']\n",
    "\n",
    "# Define index range to use 'iloc'\n",
    "index_range = range(0, len(final_df))\n",
    "\n",
    "# Final Return variables\n",
    "qa_results = []\n",
    "context_qa_results = []\n",
    "cot_qa_results = []\n",
    "\n",
    "# Run a evaluation\n",
    "for i in index_range:\n",
    "    qa_result = evaluator_qa.evaluate_strings(\n",
    "        input = final_df['query'].iloc[i],\n",
    "        prediction = final_df['predict'].iloc[i],\n",
    "        reference = final_df['label'].iloc[i]\n",
    "    )\n",
    "\n",
    "    context_qa_result = evaluator_context_qa.evaluate_strings(\n",
    "        input = final_df['query'].iloc[i],\n",
    "        prediction = final_df['predict'].iloc[i],\n",
    "        reference = final_df['label'].iloc[i]\n",
    "    )\n",
    "\n",
    "    cot_qa_result = evaluator_cot_qa.evaluate_strings(\n",
    "        input = final_df['query'].iloc[i],\n",
    "        prediction = final_df['predict'].iloc[i],\n",
    "        reference = final_df['label'].iloc[i]\n",
    "    )\n",
    "\n",
    "    qa_results.append(qa_result)\n",
    "    context_qa_results.append(context_qa_result)\n",
    "    cot_qa_results.append(cot_qa_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7effbec",
   "metadata": {},
   "source": [
    "## **Check Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bc30826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "general_qa       0.80\n",
       "context_qa       0.85\n",
       "cot_qa_result    0.90\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract scores\n",
    "qa_results_score = [result['score'] for result in qa_results]\n",
    "context_qa_results_score = [result['score'] for result in context_qa_results]\n",
    "cot_qa_results_score = [result['score'] for result in cot_qa_results]\n",
    "\n",
    "# Add columns into final_df\n",
    "final_df['general_qa'] = qa_results_score\n",
    "final_df['context_qa'] = context_qa_results_score\n",
    "final_df['cot_qa_result'] = cot_qa_results_score\n",
    "\n",
    "# Save to final result\n",
    "final_df.to_csv('./data/evaluated_question_paper.csv')\n",
    "\n",
    "# Select metrics\n",
    "scores = final_df[['general_qa', 'context_qa', 'cot_qa_result']]\n",
    "\n",
    "# Print metrics\n",
    "scores.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ga_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
